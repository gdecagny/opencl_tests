{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import pyopencl.characterize.performance as perf\n",
    "import numpy as np\n",
    "import time, math, sys\n",
    "\n",
    "mf = cl.mem_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<pyopencl.Context at 0x56354c227100 on <pyopencl.Device 'Tesla K80' on 'NVIDIA CUDA' at 0x56354bcb3040>>,\n",
       "  <pyopencl.cffi_cl.CommandQueue at 0x7f0c301304d0>),\n",
       " (<pyopencl.Context at 0x56354cd25760 on <pyopencl.Device 'pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz' on 'Portable Computing Language' at 0x56354bdef9a0>>,\n",
       "  <pyopencl.cffi_cl.CommandQueue at 0x7f0c30130550>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "cq = []\n",
    "for platform in platforms:\n",
    "    for dev in platform.get_devices():\n",
    "        context = cl.Context(devices=[dev])\n",
    "        queue = cl.CommandQueue(context=context, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "        cq.append(( context, queue ))\n",
    "\n",
    "cq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## create test harness and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def prettyprint(table):\n",
    "    display(HTML('<table><tr>{0}</tr></table>'.format(\n",
    "    \"</tr><tr>\".join( '<td>{}</td>'.format( \n",
    "        '</td><td>'.join(str(_) for _ in row)) for row in table )\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(harness_builder = lambda context, queue, N: (lambda:None), count=10, N=1024):\n",
    "    out = [ [ \" \" ] + [ cqu[0].devices[0].name for cqu in cq ], [ \"Program Time (ms)\"], [ \"Copy buffer out time (ms)\"], [ \"MFLOPS\" ] ]\n",
    "    for context, queue in cq:\n",
    "        pgmtimes = []\n",
    "        copytimes = []\n",
    "        harness, expected_reply = harness_builder(context, queue, N)\n",
    "        print >> sys.stderr, \"Testing with\", context.devices[0].name\n",
    "        result = None\n",
    "        for i in xrange(count):\n",
    "            try:\n",
    "                result, evt_pgm, evt_copyout = harness()\n",
    "            except Exception, e:\n",
    "                print >> sys.stderr, \"Exception on\", context.devices[0].name, str(e)\n",
    "                break\n",
    "            pgmtimes.append((evt_pgm.profile.end-evt_pgm.profile.start)*1e-6)\n",
    "            copytimes.append((evt_copyout.profile.end-evt_copyout.profile.start)*1e-6)\n",
    "            if expected_reply is not None:\n",
    "                if ( (result-expected_reply) > 0.01 ).any():\n",
    "                    print >> sys.stderr, \"Warning! wrong result on\", context.devices[0].name\n",
    "            else:\n",
    "                print >> sys.stderr, 'No expected reply'\n",
    "        if pgmtimes:\n",
    "            out[1].append('{0:.3f}'.format( np.average(pgmtimes) ) )\n",
    "            out[2].append('{0:.3f}'.format( np.average(copytimes) ) )\n",
    "            out[3].append('{0:.0f}'.format( 2.0 * N * N * N/(1000.0*np.average(pgmtimes)) ) )\n",
    "        else:\n",
    "            out[1].append(\"N/A\")\n",
    "            out[2].append(\"N/A\")\n",
    "            out[3].append(\"N/A\")\n",
    "\n",
    "    prettyprint(out)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view CPU/GPU capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>max work item size</td><td>[1024L, 1024L, 64L]</td><td>[4096L, 4096L, 4096L]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = [ [ \" \" ] + [ cqu[0].devices[0].name for cqu in cq ] ]\n",
    "out += [ [ \"max work item size\" ] + [ cqu[0].devices[0].max_work_item_sizes for cqu in cq ] ]\n",
    "prettyprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command latency: 3.53456e-05 s\n",
      "profiling overhead: 1.01333e-05 s -> 28.7 %\n",
      "empty kernel: 3.7255e-05 s\n",
      "52 1879028.31766 0\n",
      "104 3835450.78812 0\n",
      "208 7988087.50095 0\n",
      "416 15955790.065 0\n",
      "832 31998633.0763 0\n",
      "1664 64255221.6445 0\n",
      "3328 130489866.212 0\n",
      "6656 259592689.984 0\n",
      "13312 522724522.54 0\n",
      "26624 1050030939.06 0\n",
      "53248 2083191403.69 0\n",
      "106496 4166000294.69 0\n",
      "212992 8363494486.62 0\n",
      "425984 16325922387.3 0\n",
      "851968 33097977431.5 0\n",
      "1703936 61802616313.7 0\n",
      "3407872 81737704351.0 0\n",
      "6815744 93056488803.2 0\n",
      "13631488 99716360113.0 0\n",
      "27262976 1.03450869848e+11 0\n",
      "float32 add: 51725.4 GOps/s\n",
      "----------------------------------------\n",
      "HostToDeviceTransfer\n",
      "----------------------------------------\n",
      "latency: 4.49203e-05 s\n",
      "bandwidth @ 64 bytes: 0.00142473 GB/s\n",
      "bandwidth @ 256 bytes: 0.00569969 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0226423 GB/s\n",
      "bandwidth @ 4096 bytes: 0.089303 GB/s\n",
      "bandwidth @ 16384 bytes: 0.333265 GB/s\n",
      "bandwidth @ 65536 bytes: 1.08777 GB/s\n",
      "bandwidth @ 262144 bytes: 2.80674 GB/s\n",
      "bandwidth @ 1048576 bytes: 4.88352 GB/s\n",
      "bandwidth @ 4194304 bytes: 7.95553 GB/s\n",
      "bandwidth @ 16777216 bytes: 9.61031 GB/s\n",
      "bandwidth @ 67108864 bytes: 10.079 GB/s\n",
      "bandwidth @ 268435456 bytes: 10.2629 GB/s\n",
      "bandwidth @ 1073741824 bytes: 10.342 GB/s\n",
      "----------------------------------------\n",
      "DeviceToHostTransfer\n",
      "----------------------------------------\n",
      "latency: 5.01584e-05 s\n",
      "bandwidth @ 64 bytes: 0.00125976 GB/s\n",
      "bandwidth @ 256 bytes: 0.00505455 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0201538 GB/s\n",
      "bandwidth @ 4096 bytes: 0.0793241 GB/s\n",
      "bandwidth @ 16384 bytes: 0.300662 GB/s\n",
      "bandwidth @ 65536 bytes: 1.0255 GB/s\n",
      "bandwidth @ 262144 bytes: 2.63522 GB/s\n",
      "bandwidth @ 1048576 bytes: 4.61248 GB/s\n",
      "bandwidth @ 4194304 bytes: 8.22871 GB/s\n",
      "bandwidth @ 16777216 bytes: 10.3888 GB/s\n",
      "bandwidth @ 67108864 bytes: 11.1548 GB/s\n",
      "bandwidth @ 268435456 bytes: 11.3494 GB/s\n",
      "bandwidth @ 1073741824 bytes: 11.4558 GB/s\n",
      "----------------------------------------\n",
      "DeviceToDeviceTransfer\n",
      "----------------------------------------\n",
      "latency: 3.46716e-05 s\n",
      "bandwidth @ 64 bytes: 0.00182528 GB/s\n",
      "bandwidth @ 256 bytes: 0.00721254 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0288771 GB/s\n",
      "bandwidth @ 4096 bytes: 0.116239 GB/s\n",
      "bandwidth @ 16384 bytes: 0.460335 GB/s\n",
      "bandwidth @ 65536 bytes: 1.8785 GB/s\n",
      "bandwidth @ 262144 bytes: 7.48575 GB/s\n",
      "bandwidth @ 1048576 bytes: 30.0541 GB/s\n",
      "bandwidth @ 4194304 bytes: 66.5657 GB/s\n",
      "bandwidth @ 16777216 bytes: 76.9221 GB/s\n",
      "bandwidth @ 67108864 bytes: 79.9855 GB/s\n",
      "bandwidth @ 268435456 bytes: 80.8145 GB/s\n",
      "bandwidth @ 1073741824 bytes: 80.9896 GB/s\n",
      "command latency: 2.8947e-05 s\n",
      "profiling overhead: -1.06432e-07 s -> -0.4 %\n",
      "empty kernel: 2.52728e-05 s\n",
      "16 629576.897064 0\n",
      "32 1282252.03266 0\n",
      "64 2607937.9045 0\n",
      "128 5009540.70618 0\n",
      "256 10095264.7583 0\n",
      "512 19898473.2137 0\n",
      "1024 40251324.7754 0\n",
      "2048 82463701.938 0\n",
      "4096 167388782.067 0\n",
      "8192 325499123.804 0\n",
      "16384 677025630.815 0\n",
      "32768 1292894742.81 0\n",
      "65536 2937681147.48 0\n",
      "131072 5513314156.99 0\n",
      "262144 11444603063.1 0\n",
      "524288 23853811585.6 0\n",
      "1048576 55961353751.1 0\n",
      "2097152 85509220539.4 0\n",
      "4194304 1.30886024506e+11 0\n",
      "8388608 1.70890730531e+11 0\n",
      "16777216 2.22982709747e+11 0\n",
      "33554432 2.69600549757e+11 0\n",
      "67108864 2.99452324801e+11 0\n",
      "134217728 3.15401172384e+11 0\n",
      "268435456 3.28957408673e+11 0\n",
      "float32 add: 164479 GOps/s\n",
      "----------------------------------------\n",
      "HostToDeviceTransfer\n",
      "----------------------------------------\n",
      "latency: 6.5148e-05 s\n",
      "bandwidth @ 64 bytes: 0.00102947 GB/s\n",
      "bandwidth @ 256 bytes: 0.00383855 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0166095 GB/s\n",
      "bandwidth @ 4096 bytes: 0.0604493 GB/s\n",
      "bandwidth @ 16384 bytes: 0.22944 GB/s\n",
      "bandwidth @ 65536 bytes: 0.991364 GB/s\n",
      "bandwidth @ 262144 bytes: 2.86002 GB/s\n",
      "bandwidth @ 1048576 bytes: 6.24743 GB/s\n",
      "bandwidth @ 4194304 bytes: 8.85767 GB/s\n",
      "bandwidth @ 16777216 bytes: 6.33991 GB/s\n",
      "bandwidth @ 67108864 bytes: 11.1158 GB/s\n",
      "bandwidth @ 268435456 bytes: 11.2455 GB/s\n",
      "bandwidth @ 1073741824 bytes: 11.3551 GB/s\n",
      "----------------------------------------\n",
      "DeviceToHostTransfer\n",
      "----------------------------------------\n",
      "latency: 6.31397e-05 s\n",
      "bandwidth @ 64 bytes: 0.000908526 GB/s\n",
      "bandwidth @ 256 bytes: 0.00365365 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0158712 GB/s\n",
      "bandwidth @ 4096 bytes: 0.0609756 GB/s\n",
      "bandwidth @ 16384 bytes: 0.259716 GB/s\n",
      "bandwidth @ 65536 bytes: 1.00367 GB/s\n",
      "bandwidth @ 262144 bytes: 3.45241 GB/s\n",
      "bandwidth @ 1048576 bytes: 7.93834 GB/s\n",
      "bandwidth @ 4194304 bytes: 10.0588 GB/s\n",
      "bandwidth @ 16777216 bytes: 10.0177 GB/s\n",
      "bandwidth @ 67108864 bytes: 11.2156 GB/s\n",
      "bandwidth @ 268435456 bytes: 11.2171 GB/s\n",
      "bandwidth @ 1073741824 bytes: 11.2589 GB/s\n",
      "----------------------------------------\n",
      "DeviceToDeviceTransfer\n",
      "----------------------------------------\n",
      "latency: 2.89426e-05 s\n",
      "bandwidth @ 64 bytes: 0.00223269 GB/s\n",
      "bandwidth @ 256 bytes: 0.00902074 GB/s\n",
      "bandwidth @ 1024 bytes: 0.0347909 GB/s\n",
      "bandwidth @ 4096 bytes: 0.143476 GB/s\n",
      "bandwidth @ 16384 bytes: 0.571163 GB/s\n",
      "bandwidth @ 65536 bytes: 2.44085 GB/s\n",
      "bandwidth @ 262144 bytes: 9.55086 GB/s\n",
      "bandwidth @ 1048576 bytes: 13.6391 GB/s\n",
      "bandwidth @ 4194304 bytes: 15.8915 GB/s\n",
      "bandwidth @ 16777216 bytes: 13.8566 GB/s\n",
      "bandwidth @ 67108864 bytes: 11.4144 GB/s\n",
      "bandwidth @ 268435456 bytes: 11.3455 GB/s\n",
      "bandwidth @ 1073741824 bytes: 11.3409 GB/s\n"
     ]
    }
   ],
   "source": [
    "for ctx, queue in cq:\n",
    "    prof_overhead, latency = perf.get_profiling_overhead(ctx)\n",
    "    print(\"command latency: %g s\" % latency)\n",
    "    print(\"profiling overhead: %g s -> %.1f %%\" % (\n",
    "            prof_overhead, 100*prof_overhead/latency))\n",
    "    queue = cl.CommandQueue(\n",
    "            ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "    print(\"empty kernel: %g s\" % perf.get_empty_kernel_time(queue))\n",
    "    print(\"float32 add: %g GOps/s\" % (perf.get_add_rate(queue)/1e9))\n",
    "\n",
    "    for tx_type in [\n",
    "            perf.HostToDeviceTransfer,\n",
    "            perf.DeviceToHostTransfer,\n",
    "            perf.DeviceToDeviceTransfer]:\n",
    "        print(\"----------------------------------------\")\n",
    "        print(tx_type.__name__)\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "        print(\"latency: %g s\" % perf.transfer_latency(queue, tx_type))\n",
    "        for i in range(6, 31, 2):\n",
    "            bs = 1 << i\n",
    "            try:\n",
    "                result = \"%g GB/s\" % (perf.transfer_bandwidth(queue, tx_type, bs)/1e9)\n",
    "            except Exception as e:\n",
    "                result = \"exception: %s\" % e.__class__.__name__\n",
    "            print(\"bandwidth @ %d bytes: %s\" % (bs, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_basic(context, queue, N):\n",
    "    h_A = np.random.rand(N,N).astype(np.float32)\n",
    "    h_B = np.random.rand(N,N).astype(np.float32)\n",
    "    h_C = np.empty([N,N]).astype(np.float32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource_basic = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j = get_global_id(1);\n",
    "            __private uint k;\n",
    "            __private float tmp = 0.0f;\n",
    "            for (k=0; k<count; k++) {\n",
    "                tmp += A[ i*count + k ] * B [ k*count + j ];\n",
    "            }\n",
    "            out[i*count + j] = tmp;\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource_basic).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        evt_pgm = mmul(queue, h_A.shape, None, d_A, d_B, d_C, N)\n",
    "        evt_copy = cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, evt_pgm, evt_copy\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>224.517</td><td>1367.970</td></tr><tr><td>Copy buffer out time (ms)</td><td>0.481</td><td>1.396</td></tr><tr><td>MFLOPS</td><td>9565</td><td>1570</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_basic, 10, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version with row as work-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_row_as_workitem(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j, k;\n",
    "            for (j=0; j<count; j++)\n",
    "            {\n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += A[ i*count + k ] * B [ k*count + j ];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        evt_pgm =mmul(queue, (count,), (32,), d_A, d_B, d_C, count)\n",
    "        evt_copy =cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, evt_pgm, evt_copy\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>474.540</td><td>1413.832</td></tr><tr><td>Copy buffer out time (ms)</td><td>0.465</td><td>1.288</td></tr><tr><td>MFLOPS</td><td>4525</td><td>1519</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_row_as_workitem, 10, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version with row stored in private memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_row_cached_in_private(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j, k;\n",
    "            __private float Arwk[\"\"\"+str(count)+\"\"\"];\n",
    "            \n",
    "            for (k=0; k<count; k++)\n",
    "                Arwk[k] = A[i*count+k];\n",
    "            \n",
    "            for (j=0; j<count; j++)\n",
    "            {\n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += Arwk[k] * B [ k*count + j ];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        evt_pgm = mmul(queue, (count,), None, d_A, d_B, d_C, count)\n",
    "        evt_copy = cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, evt_pgm, evt_copy\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>223.477</td><td>2076.648</td></tr><tr><td>Copy buffer out time (ms)</td><td>0.466</td><td>1.285</td></tr><tr><td>MFLOPS</td><td>9609</td><td>1034</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_row_cached_in_private, 10, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version with local memory for the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_privateA_localB(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          __local float* Bwrk,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint iloc = get_local_id(0);\n",
    "            __private uint nloc = get_local_size(0);\n",
    "            __private uint j, k;\n",
    "            __private float Arwk[\"\"\"+str(count)+\"\"\"];\n",
    "            \n",
    "            for (k=0; k<count; k++)\n",
    "                Arwk[k] = A[i*count+k];\n",
    "            \n",
    "            for (j=0; j < count; j++)\n",
    "            {\n",
    "                for( k = iloc; k<count; k+=nloc)\n",
    "                {\n",
    "                    Bwrk[k] = B[ k*count + j ];\n",
    "                }\n",
    "            \n",
    "                barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                \n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += Arwk[k] * Bwrk[k];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "                \n",
    "                barrier(CLK_LOCAL_MEM_FENCE);\n",
    "            }\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local = cl.LocalMemory(count*4)\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        evt_pgm = mmul(queue, (count,), None, d_A, d_B, d_C, local, count)\n",
    "        evt_copy = cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, evt_pgm, evt_copy\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>156.594</td><td>2581.983</td></tr><tr><td>Copy buffer out time (ms)</td><td>0.517</td><td>1.297</td></tr><tr><td>MFLOPS</td><td>13714</td><td>832</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_privateA_localB, 2, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version split by blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_blocks(context, queue, count):\n",
    "    h_A = np.random.rand(count,count).astype(np.float32)\n",
    "    h_B = np.random.rand(count,count).astype(np.float32)\n",
    "    h_C = np.empty([count,count]).astype(np.float32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes*4)\n",
    "    \n",
    "    BLOCK_SIZE = 32\n",
    "    kernelsource = \"\"\"\n",
    "\n",
    "        #define BLOCK_SIZE \"\"\"+str(BLOCK_SIZE)+\"\"\"\n",
    "        //#define count \"\"\"+str(count)+\"\"\"\n",
    "        \n",
    "        #define ASUB(i, j) Asub[i + j*BLOCK_SIZE]\n",
    "        #define BSUB(i, j) Bsub[i + j*BLOCK_SIZE]\n",
    "\n",
    "\n",
    "\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global       float* out,\n",
    "                          __local float* Asub,\n",
    "                          __local float* Bsub,\n",
    "                          __private uint count)\n",
    "        {\n",
    "        \n",
    "            // this processing element has to compute out[ get_global_id(0), get_global_id(1) ]\n",
    "            \n",
    "            uint block_id_x = get_group_id(0);\n",
    "            uint block_id_y = get_group_id(1);\n",
    "            \n",
    "            uint x_thread = get_local_id(0);\n",
    "            uint y_thread = get_local_id(1);\n",
    "\n",
    "            uint aStart = block_id_y * BLOCK_SIZE * count;\n",
    "            uint aStep = BLOCK_SIZE;\n",
    "            uint aEnd = aStart + count - 1;\n",
    "            \n",
    "            uint bStart = block_id_x * BLOCK_SIZE;\n",
    "            uint bStep = BLOCK_SIZE * count;\n",
    "            \n",
    "            __private float Csub = 0.0f;\n",
    "            \n",
    "            for (uint a = aStart, b = bStart;\n",
    "                 a <= aEnd;\n",
    "                 a += aStep, b+= bStep)\n",
    "                 {\n",
    "                     ASUB(x_thread, y_thread) = A[a + count * y_thread + x_thread];\n",
    "                     BSUB(x_thread, y_thread) = B[b + count * y_thread + x_thread];\n",
    "                     \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                     \n",
    "                     #pragma unroll\n",
    "                     for( uint k =0; k < BLOCK_SIZE; ++k)\n",
    "                         Csub += ASUB(k, y_thread) * BSUB(x_thread, k);\n",
    "                         \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                 }\n",
    "                 \n",
    "            out[get_global_id(1) * count + get_global_id(0)] = Csub;\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local_a = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    local_b = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        event_pgm = mmul(queue, (count,count), (BLOCK_SIZE,BLOCK_SIZE), d_A, d_B, d_C, local_a, local_b, count)\n",
    "        event_copy_out = cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, event_pgm, event_copy_out\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>72.802</td><td>9168.330</td></tr><tr><td>Copy buffer out time (ms)</td><td>1.842</td><td>5.059</td></tr><tr><td>MFLOPS</td><td>235981</td><td>1874</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_blocks, 1, 1024*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version split by blocks - Integer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_blocks_int(context, queue, count):\n",
    "    h_A = np.random.rand(count,count).astype(np.int32)\n",
    "    h_B = np.random.rand(count,count).astype(np.int32)\n",
    "    h_C = np.empty([count,count]).astype(np.int32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes*4)\n",
    "    \n",
    "    BLOCK_SIZE = 16\n",
    "    kernelsource = \"\"\"\n",
    "\n",
    "        #define BLOCK_SIZE \"\"\"+str(BLOCK_SIZE)+\"\"\"\n",
    "        //#define count \"\"\"+str(count)+\"\"\"\n",
    "        \n",
    "        #define ASUB(i, j) Asub[i + j*BLOCK_SIZE]\n",
    "        #define BSUB(i, j) Bsub[i + j*BLOCK_SIZE]\n",
    "\n",
    "\n",
    "\n",
    "       __kernel void mmul(__global const int* A,\n",
    "                          __global const int* B,\n",
    "                          __global       int* out,\n",
    "                          __local int* Asub,\n",
    "                          __local int* Bsub,\n",
    "                          __private uint count)\n",
    "        {\n",
    "        \n",
    "            // this processing element has to compute out[ get_global_id(0), get_global_id(1) ]\n",
    "            \n",
    "            uint block_id_x = get_group_id(0);\n",
    "            uint block_id_y = get_group_id(1);\n",
    "            \n",
    "            uint x_thread = get_local_id(0);\n",
    "            uint y_thread = get_local_id(1);\n",
    "\n",
    "            uint aStart = block_id_y * BLOCK_SIZE * count;\n",
    "            uint aStep = BLOCK_SIZE;\n",
    "            uint aEnd = aStart + count - 1;\n",
    "            \n",
    "            uint bStart = block_id_x * BLOCK_SIZE;\n",
    "            uint bStep = BLOCK_SIZE * count;\n",
    "            \n",
    "            __private int Csub = 0;\n",
    "            \n",
    "            for (uint a = aStart, b = bStart;\n",
    "                 a <= aEnd;\n",
    "                 a += aStep, b+= bStep)\n",
    "                 {\n",
    "                     ASUB(x_thread, y_thread) = A[a + count * y_thread + x_thread];\n",
    "                     BSUB(x_thread, y_thread) = B[b + count * y_thread + x_thread];\n",
    "                     \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                     \n",
    "                     #pragma unroll\n",
    "                     for( uint k =0; k < BLOCK_SIZE; ++k)\n",
    "                         Csub += ASUB(k, y_thread) * BSUB(x_thread, k);\n",
    "                         \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                 }\n",
    "                 \n",
    "            out[get_global_id(1) * count + get_global_id(0)] = Csub;\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local_a = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    local_b = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        evt_pgm = mmul(queue, (count,count), (BLOCK_SIZE,BLOCK_SIZE), d_A, d_B, d_C, local_a, local_b, count)\n",
    "        evt_copy = cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C, evt_pgm, evt_copy\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Program Time (ms)</td><td>112.748</td><td>9939.520</td></tr><tr><td>Copy buffer out time (ms)</td><td>2.207</td><td>4.934</td></tr><tr><td>MFLOPS</td><td>152374</td><td>1728</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_blocks_int, 1, 1024*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
