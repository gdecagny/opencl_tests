{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "import time, math, sys\n",
    "\n",
    "mf = cl.mem_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<pyopencl.Context at 0x55e7891cc010 on <pyopencl.Device 'Tesla K80' on 'NVIDIA CUDA' at 0x55e7891ddbe0>>,\n",
       "  <pyopencl.cffi_cl.CommandQueue at 0x7f6de227afd0>),\n",
       " (<pyopencl.Context at 0x55e78a021e80 on <pyopencl.Device 'pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz' on 'Portable Computing Language' at 0x55e78952d950>>,\n",
       "  <pyopencl.cffi_cl.CommandQueue at 0x7f6de2287090>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "cq = []\n",
    "for platform in platforms:\n",
    "    for dev in platform.get_devices():\n",
    "        context = cl.Context(devices=[dev])\n",
    "        queue = cl.CommandQueue(context=context)\n",
    "        cq.append(( context, queue ))\n",
    "\n",
    "cq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## create test harness and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def prettyprint(table):\n",
    "    display(HTML('<table><tr>{0}</tr></table>'.format(\n",
    "    \"</tr><tr>\".join( '<td>{}</td>'.format( \n",
    "        '</td><td>'.join(str(_) for _ in row)) for row in table )\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(harness_builder = lambda context, queue, N: (lambda:None), count=10, N=1024):\n",
    "    out = [ [ \" \" ] + [ cqu[0].devices[0].name for cqu in cq ], [ \"Time (ms)\"], [ \"MFLOPS\" ] ]\n",
    "    for context, queue in cq:\n",
    "        times = []\n",
    "        harness, expected_reply = harness_builder(context, queue, N)\n",
    "        print >> sys.stderr, \"Testing with\", context.devices[0].name\n",
    "        result = None\n",
    "        for i in xrange(count):\n",
    "            time_start = time.time()\n",
    "            try:\n",
    "                result = harness()\n",
    "            except Exception, e:\n",
    "                print >> sys.stderr, \"Exception on\", context.devices[0].name, str(e)\n",
    "                break\n",
    "            times.append(time.time() - time_start)\n",
    "            if expected_reply is not None:\n",
    "                if ( (result-expected_reply) > 0.1 ).any():\n",
    "                    print >> sys.stderr, \"Warning! wrong result on\", context.devices[0].name\n",
    "            else:\n",
    "                print >> sys.stderr, 'No expected reply'\n",
    "        if times:\n",
    "            out[1].append('{0:.3f}'.format( np.average(times)*1000 ) )\n",
    "            out[2].append('{0:.0f}'.format( 2.0 * N * N * N/(1000000.0*np.average(times)) ) )\n",
    "        else:\n",
    "            out[1].append(\"N/A\")\n",
    "            out[2].append(\"N/A\")\n",
    "\n",
    "    prettyprint(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n",
      "No expected reply\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Time (ms)</td><td>1.120</td><td>1.113</td></tr><tr><td>MFLOPS</td><td>1916711</td><td>1928613</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(lambda a,b,c: (lambda: time.sleep(0.001), None), 10, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>CPU</td><td>GPU</td></tr><tr><td>1</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prettyprint([ [ 'CPU', 'GPU' ], [1, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view CPU/GPU capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>max work item size</td><td>[1024L, 1024L, 64L]</td><td>[4096L, 4096L, 4096L]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = [ [ \" \" ] + [ cqu[0].devices[0].name for cqu in cq ] ]\n",
    "out += [ [ \"max work item size\" ] + [ cqu[0].devices[0].max_work_item_sizes for cqu in cq ] ]\n",
    "prettyprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_basic(context, queue, N):\n",
    "    h_A = np.random.rand(N,N).astype(np.float32)\n",
    "    h_B = np.random.rand(N,N).astype(np.float32)\n",
    "    h_C = np.empty([N,N]).astype(np.float32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource_basic = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j = get_global_id(1);\n",
    "            __private uint k;\n",
    "            __private float tmp = 0.0f;\n",
    "            for (k=0; k<count; k++) {\n",
    "                tmp += A[ i*count + k ] * B [ k*count + j ];\n",
    "            }\n",
    "            out[i*count + j] = tmp;\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource_basic).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, h_A.shape, None, d_A, d_B, d_C, N)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(harnessbuilder_basic, 10, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version with row as work-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_row_as_workitem(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j, k;\n",
    "            for (j=0; j<count; j++)\n",
    "            {\n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += A[ i*count + k ] * B [ k*count + j ];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, (count,), (32,), d_A, d_B, d_C, count)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test(harnessbuilder_row_as_workitem, 10, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version with row stored in private memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_row_cached_in_private(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint j, k;\n",
    "            __private float Arwk[\"\"\"+str(count)+\"\"\"];\n",
    "            \n",
    "            for (k=0; k<count; k++)\n",
    "                Arwk[k] = A[i*count+k];\n",
    "            \n",
    "            for (j=0; j<count; j++)\n",
    "            {\n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += Arwk[k] * B [ k*count + j ];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, (count,), None, d_A, d_B, d_C, count)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test(harnessbuilder_row_cached_in_private, 10, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version with local memory for the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_privateA_localB(context, queue, count):\n",
    "    h_A = np.random.rand(count**2).astype(np.float32)\n",
    "    h_B = np.random.rand(count**2).astype(np.float32)\n",
    "    h_C = np.empty([count**2]).astype(np.float32)\n",
    "    expected_reply = h_A.reshape(count,count).dot(h_B.reshape(count,count)).reshape(count**2)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes)\n",
    "    kernelsource = \"\"\"\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global float* out,\n",
    "                          __local float* Bwrk,\n",
    "                          uint count)\n",
    "        {\n",
    "            __private uint i = get_global_id(0);\n",
    "            __private uint iloc = get_local_id(0);\n",
    "            __private uint nloc = get_local_size(0);\n",
    "            __private uint j, k;\n",
    "            __private float Arwk[\"\"\"+str(count)+\"\"\"];\n",
    "            \n",
    "            for (k=0; k<count; k++)\n",
    "                Arwk[k] = A[i*count+k];\n",
    "            \n",
    "            for (j=0; j < count; j++)\n",
    "            {\n",
    "                for( k = iloc; k<count; k+=nloc)\n",
    "                {\n",
    "                    Bwrk[k] = B[ k*count + j ];\n",
    "                }\n",
    "            \n",
    "                barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                \n",
    "                __private float tmp = 0.0f;\n",
    "                for (k=0; k<count; k++) {\n",
    "                    tmp += Arwk[k] * Bwrk[k];\n",
    "                }\n",
    "                out[i*count + j] = tmp;\n",
    "                \n",
    "                barrier(CLK_LOCAL_MEM_FENCE);\n",
    "            }\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local = cl.LocalMemory(count*4)\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, (count,), None, d_A, d_B, d_C, local, count)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test(harnessbuilder_privateA_localB, 2, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version split by blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_blocks(context, queue, count):\n",
    "    h_A = np.random.rand(count,count).astype(np.float32)\n",
    "    h_B = np.random.rand(count,count).astype(np.float32)\n",
    "    h_C = np.empty([count,count]).astype(np.float32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes*4)\n",
    "    \n",
    "    BLOCK_SIZE = 16\n",
    "    kernelsource = \"\"\"\n",
    "\n",
    "        #define BLOCK_SIZE \"\"\"+str(BLOCK_SIZE)+\"\"\"\n",
    "        //#define count \"\"\"+str(count)+\"\"\"\n",
    "        \n",
    "        #define ASUB(i, j) Asub[i + j*BLOCK_SIZE]\n",
    "        #define BSUB(i, j) Bsub[i + j*BLOCK_SIZE]\n",
    "\n",
    "\n",
    "\n",
    "       __kernel void mmul(__global const float* A,\n",
    "                          __global const float* B,\n",
    "                          __global       float* out,\n",
    "                          __local float* Asub,\n",
    "                          __local float* Bsub,\n",
    "                          __private uint count)\n",
    "        {\n",
    "        \n",
    "            // this processing element has to compute out[ get_global_id(0), get_global_id(1) ]\n",
    "            \n",
    "            uint block_id_x = get_group_id(0);\n",
    "            uint block_id_y = get_group_id(1);\n",
    "            \n",
    "            uint x_thread = get_local_id(0);\n",
    "            uint y_thread = get_local_id(1);\n",
    "\n",
    "            uint aStart = block_id_y * BLOCK_SIZE * count;\n",
    "            uint aStep = BLOCK_SIZE;\n",
    "            uint aEnd = aStart + count - 1;\n",
    "            \n",
    "            uint bStart = block_id_x * BLOCK_SIZE;\n",
    "            uint bStep = BLOCK_SIZE * count;\n",
    "            \n",
    "            __private float Csub = 0.0f;\n",
    "            \n",
    "            for (uint a = aStart, b = bStart;\n",
    "                 a <= aEnd;\n",
    "                 a += aStep, b+= bStep)\n",
    "                 {\n",
    "                     ASUB(x_thread, y_thread) = A[a + count * y_thread + x_thread];\n",
    "                     BSUB(x_thread, y_thread) = B[b + count * y_thread + x_thread];\n",
    "                     \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                     \n",
    "                     #pragma unroll\n",
    "                     for( uint k =0; k < BLOCK_SIZE; ++k)\n",
    "                         Csub += ASUB(k, y_thread) * BSUB(x_thread, k);\n",
    "                         \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                 }\n",
    "                 \n",
    "            out[get_global_id(1) * count + get_global_id(0)] = Csub;\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local_a = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    local_b = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, (count,count), (BLOCK_SIZE,BLOCK_SIZE), d_A, d_B, d_C, local_a, local_b, count)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test(harnessbuilder_blocks, 1, 1024*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## version split by blocks - Integer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harnessbuilder_blocks_int(context, queue, count):\n",
    "    h_A = np.random.rand(count,count).astype(np.int32)\n",
    "    h_B = np.random.rand(count,count).astype(np.int32)\n",
    "    h_C = np.empty([count,count]).astype(np.int32)\n",
    "    expected_reply = h_A.dot(h_B)\n",
    "    \n",
    "    d_A = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_A)\n",
    "    d_B = cl.Buffer(context, mf.COPY_HOST_PTR | mf.READ_ONLY, hostbuf=h_B)\n",
    "    d_C = cl.Buffer(context, mf.WRITE_ONLY, h_C.nbytes*4)\n",
    "    \n",
    "    BLOCK_SIZE = 16\n",
    "    kernelsource = \"\"\"\n",
    "\n",
    "        #define BLOCK_SIZE \"\"\"+str(BLOCK_SIZE)+\"\"\"\n",
    "        //#define count \"\"\"+str(count)+\"\"\"\n",
    "        \n",
    "        #define ASUB(i, j) Asub[i + j*BLOCK_SIZE]\n",
    "        #define BSUB(i, j) Bsub[i + j*BLOCK_SIZE]\n",
    "\n",
    "\n",
    "\n",
    "       __kernel void mmul(__global const int* A,\n",
    "                          __global const int* B,\n",
    "                          __global       int* out,\n",
    "                          __local int* Asub,\n",
    "                          __local int* Bsub,\n",
    "                          __private uint count)\n",
    "        {\n",
    "        \n",
    "            // this processing element has to compute out[ get_global_id(0), get_global_id(1) ]\n",
    "            \n",
    "            uint block_id_x = get_group_id(0);\n",
    "            uint block_id_y = get_group_id(1);\n",
    "            \n",
    "            uint x_thread = get_local_id(0);\n",
    "            uint y_thread = get_local_id(1);\n",
    "\n",
    "            uint aStart = block_id_y * BLOCK_SIZE * count;\n",
    "            uint aStep = BLOCK_SIZE;\n",
    "            uint aEnd = aStart + count - 1;\n",
    "            \n",
    "            uint bStart = block_id_x * BLOCK_SIZE;\n",
    "            uint bStep = BLOCK_SIZE * count;\n",
    "            \n",
    "            __private int Csub = 0;\n",
    "            \n",
    "            for (uint a = aStart, b = bStart;\n",
    "                 a <= aEnd;\n",
    "                 a += aStep, b+= bStep)\n",
    "                 {\n",
    "                     ASUB(x_thread, y_thread) = A[a + count * y_thread + x_thread];\n",
    "                     BSUB(x_thread, y_thread) = B[b + count * y_thread + x_thread];\n",
    "                     \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                     \n",
    "                     #pragma unroll\n",
    "                     for( uint k =0; k < BLOCK_SIZE; ++k)\n",
    "                         Csub += ASUB(k, y_thread) * BSUB(x_thread, k);\n",
    "                         \n",
    "                     barrier(CLK_LOCAL_MEM_FENCE);\n",
    "                 }\n",
    "                 \n",
    "            out[get_global_id(1) * count + get_global_id(0)] = Csub;\n",
    "                \n",
    "        }\n",
    "    \"\"\"\n",
    "    local_a = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    local_b = cl.LocalMemory(4*(BLOCK_SIZE**2))\n",
    "    program = cl.Program(context, kernelsource).build()\n",
    "    mmul = program.mmul\n",
    "    mmul.set_scalar_arg_dtypes([None,None,None,None,None,np.uint32])\n",
    "\n",
    "    def run_mmul():\n",
    "        mmul(queue, (count,count), (BLOCK_SIZE,BLOCK_SIZE), d_A, d_B, d_C, local_a, local_b, count)\n",
    "        cl.enqueue_copy(queue, h_C, d_C)\n",
    "        queue.finish()\n",
    "        return h_C\n",
    "    \n",
    "    return run_mmul, expected_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Tesla K80\n",
      "Testing with pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td> </td><td>Tesla K80</td><td>pthread-Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz</td></tr><tr><td>Time (ms)</td><td>120.566</td><td>10197.357</td></tr><tr><td>MFLOPS</td><td>142493</td><td>1685</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(harnessbuilder_blocks_int, 1, 1024*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
